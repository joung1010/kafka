## 카프카 생태계

Apache Kafka는 분산 스트리밍 플랫폼으로, 대용량의 실시간 데이터를 안정적으로 처리하고 저장할 수 있는 시스템입니다. Kafka 생태계는 이러한 Kafka의 핵심 기능을 중심으로 다양한 도구와 라이브러리들이 결합되어 구성된 환경을 의미하며, 이를 통해 데이터 파이프라인, 실시간 스트림 처리, 이벤트 기반 아키텍처 등 다양한 용도의 시스템을 구축할 수 있습니다.

다음은 Kafka 생태계를 구성하는 주요 구성 요소들입니다:

### 1. 프로듀서 (Producer)

- **역할**:프로듀서는 데이터를 생성하여 Kafka 클러스터 내 특정 토픽(topic)에 메시지를 전송하는 역할을 합니다.
- **주요 특징**:
    - **메시지 전송**: 키-값 쌍의 메시지를 전송하며, 메시지의 파티셔닝을 통해 분산 저장 및 부하 분산을 지원합니다.
    - **전송 옵션**: 동기적/비동기적 전송, 전송 보증(acknowledgment) 등의 옵션을 통해 데이터의 안정적 전달을 보장합니다.
    - **확장성**: 여러 프로듀서를 통해 대용량 데이터의 병렬 처리가 가능하며, 다양한 클라이언트 라이브러리(Java, Python, C++ 등)를 이용해 손쉽게 통합할 수 있습니다.

---

### 2. Kafka Connect

- **역할**:Kafka Connect는 Kafka 클러스터와 외부 시스템 간의 데이터 이동을 자동화하는 프레임워크입니다.
- **주요 특징**:
    - **Source 커넥터**: 외부 데이터 소스(예: 데이터베이스, 로그 파일, 클라우드 서비스 등)에서 데이터를 추출하여 Kafka 토픽에 기록합니다.(프로듀서 역할)
    - **Sink 커넥터**: Kafka 토픽에 저장된 데이터를 외부 시스템(예: 데이터 웨어하우스, 검색 엔진,JDBC, Elasticsearch 등)으로 내보냅니다.(컨슈머 역할)
    - **플러그인 기반 확장성**: 다양한 커넥터를 플러그인 형태로 지원하여, 새로운 데이터 소스나 싱크를 쉽게 추가할 수 있습니다.
    - **운영 자동화**: 분산 환경에서의 데이터 이동을 간소화하고, 스케일 아웃 및 모니터링 기능을 제공합니다.

---

### 3. 카프카 클러스터 (Kafka Cluster)

- **역할**:Kafka 클러스터는 데이터의 중심 저장소이자 전송의 허브 역할을 하며, 여러 브로커(노드)로 구성된 분산 시스템입니다.
- **주요 특징**:
    - **분산 저장 및 처리**: 각 브로커는 토픽의 여러 파티션을 저장하며, 리더-팔로워 복제 구조를 통해 데이터의 고가용성과 내결함성을 유지합니다.
    - **확장성**: 필요에 따라 브로커를 추가하여 데이터 처리량과 저장 용량을 확장할 수 있습니다.
    - **실시간 스트리밍**: 대용량의 데이터 스트림을 안정적으로 처리하며, 메시지 순서 보장 및 빠른 읽기/쓰기 성능을 제공합니다.

---

### 4. Kafka Streams

- **역할**:Kafka Streams는 Kafka 토픽에 저장된 실시간 데이터를 처리하는 자바 기반의 라이브러리로, 애플리케이션 내부에서 스트림 처리 로직을 구현할 수 있도록 지원합니다.
- **주요 특징**:
    - **실시간 데이터 처리**: 스트림 필터링, 집계, 조인, 상태 저장 연산 등 복잡한 데이터 처리 작업을 손쉽게 구현할 수 있습니다.
    - **내장형 라이브러리**: 별도의 클러스터 구성 없이 애플리케이션 내에서 직접 실행되어, 기존 Kafka 클러스터와 자연스럽게 연동됩니다.
    - **상태 관리**: 내장 상태 저장소를 사용하여, 윈도우 연산이나 집계 등의 작업에서 상태를 유지하며, 장애 복구 기능도 지원합니다.

---

### 5. 컨슈머 (Consumer) 및 스트림즈 컨슈머

- **일반 Kafka Consumer**:
    - **역할**: Kafka 클러스터의 특정 토픽에 기록된 메시지를 구독(subscribe)하여 읽어들이고, 비즈니스 로직에 따라 데이터를 처리합니다.
    - **주요 특징**:
        - **파티션 병렬 처리**: 동일한 컨슈머 그룹 내에서 파티션 단위로 메시지를 병렬로 처리하여 높은 처리량을 달성합니다.
        - **오프셋 관리**: 처리한 메시지의 위치(오프셋)를 관리하여, 장애 발생 시 재처리나 복구가 가능하도록 합니다.
- **스트림즈 컨슈머**:
    - **역할**: Kafka Streams 애플리케이션 내부에서 처리된 결과 데이터를 소비하는 역할을 하거나, 외부 애플리케이션이 Kafka Streams 애플리케이션에서 생성한 토픽을 구독하는 형태로 사용됩니다.
    - **주요 특징**:
        - **실시간 분석 후속 처리**: Kafka Streams로 처리된 데이터를 기반으로 추가적인 실시간 분석, 모니터링 또는 후속 ETL 작업을 수행할 수 있습니다.
        - **통합 처리 파이프라인**: 스트림 처리와 일반 컨슈머의 역할이 결합되어, 실시간 처리와 결과 소비가 유기적으로 이루어집니다.
  
  
    

---
  
  
### 카프카 브로커 와 클러스터

Apache Kafka의 핵심 구성 요소 중 **브로커(Broker)**, **클러스터(Cluster)**, 그리고 **ZooKeeper**는 Kafka 시스템의 안정적 운영과 분산 환경 관리를 위해 중요한 역할을 합니다. 아래에서 각 요소에 대해 자세히 설명합니다.

---

## 1. ZooKeeper

- **정의 및 역할**:

  Apache ZooKeeper는 분산 시스템을 위한 중앙 집중형 코디네이션 서비스로, Kafka 클러스터의 메타데이터와 상태 정보를 관리합니다.

- **주요 기능**:
    - **메타데이터 관리**: Kafka 브로커, 토픽, 파티션, 리더 정보 등 클러스터의 전반적인 상태를 저장하고 관리합니다.
    - **분산 코디네이션**: 브로커의 등록, 리더 선출, 장애 감지 및 복구와 같은 클러스터 관리 작업을 수행합니다.
    - **동기화와 일관성 보장**: 분산 환경에서 여러 서버 간의 동기화를 지원하여, 일관된 상태를 유지할 수 있도록 합니다.
- **최신 동향**:
    - 과거 Kafka는 클러스터 관리와 메타데이터 관리를 위해 ZooKeeper에 의존했으나, 최근 버전에서는 자체 메타데이터 관리(KRaft 모드)를 도입하여 ZooKeeper 의존성을 점차 줄여가고 있습니다.

> 코디네이션(Coordination)"은 여러 구성 요소나 프로세스가 서로 협력하고 조율되어 하나의 통일된 시스템처럼 동작하도록 하는 과정을 의미합니다.
>  

---

## 2. Kafka 클러스터 (Cluster)

- **정의 및 역할**:

  Kafka 클러스터는 여러 Kafka 브로커가 모여 하나의 분산 시스템을 이루며, 데이터의 저장, 분산 처리 및 복제를 담당합니다.(기본적으로 3개의 브로커로 구성을 권장)

- **주요 기능**:
    - **데이터 분산 저장**: 토픽은 여러 파티션으로 나뉘며, 이 파티션들은 클러스터 내 여러 브로커에 분산되어 저장됩니다.
    - **데이터 복제 및 내결함성**: 각 파티션은 복제본을 통해 여러 브로커에 저장되어, 하나의 브로커에 장애가 발생해도 데이터 손실 없이 시스템이 계속 운영됩니다.
    - **부하 분산**: 생산자(Producer)와 소비자(Consumer)의 요청이 클러스터 내 여러 브로커에 분산되어 처리되므로, 전체 시스템의 부하를 효과적으로 분산할 수 있습니다.
- **운영 관리**:

  클러스터는 토픽 생성, 파티션 할당, 복제 설정, 브로커 상태 모니터링 등 다양한 운영 작업을 통해 안정적이고 확장 가능한 데이터 스트리밍 환경을 제공합니다.


---

## 3. Kafka 브로커 (Broker)

- **정의 및 역할**:

  Kafka 브로커는 Kafka 시스템 내에서 **개별 서버** 인스턴스로, **실제 메시지를 수신, 저장 및 전송**하는 역할을 담당합니다.

- **주요 기능**:
    - **메시지 저장**: 프로듀서가 전송한 메시지를 토픽과 파티션 단위로 저장합니다.
    - **메시지 전송**: 컨슈머가 요청할 때, 해당 파티션의 메시지를 읽어 전송합니다.
    - **데이터 복제 관리**: 각 파티션의 리더와 팔로워 역할을 수행하며, 데이터의 안정성과 내결함성을 보장합니다.
- **특징**:
    - **확장성**: 필요에 따라 브로커를 추가하여 시스템의 처리량과 저장 용량을 확장할 수 있습니다.
    - **분산 처리**: 여러 브로커가 협력하여 메시지를 분산 저장 및 처리하므로, 단일 장애 지점을 제거하고 고가용성을 유지합니다.

---

### 전체 시스템 관점

1. **ZooKeeper**는 Kafka 클러스터의 상태 및 메타데이터(브로커 정보, 토픽, 파티션, 리더 정보 등)를 중앙에서 관리하며, 클러스터의 안정적인 운영과 코디네이션을 지원합니다.
2. **Kafka 클러스터**는 여러 브로커로 구성되어 데이터를 분산 저장, 복제, 부하 분산 및 내결함성을 구현함으로써 대용량 데이터 스트리밍 환경을 효과적으로 운영합니다.
3. **Kafka 브로커**는 실제 데이터의 수신, 저장 및 전송을 담당하여, 프로듀서와 컨슈머 간의 메시지 전달을 책임집니다.

### 상호 연계 및 전체 시스템 관점

1. **데이터 생산 및 저장**:
    - **프로듀서**가 생성한 메시지는 Kafka 브로커에 전송되어 저장되며, 이 메시지는 클러스터 내의 여러 브로커에 분산되어 보관됩니다.
2. **분산 운영 관리**:
    - **Kafka 클러스터**는 다수의 브로커가 협력하여 데이터 분산 저장, 부하 분산, 복제 및 장애 복구를 수행함으로써, 대용량 데이터 스트리밍 환경에서도 안정적인 운영을 보장합니다.
3. **메타데이터와 클러스터 상태 관리**:
    - **ZooKeeper**는 Kafka 클러스터의 메타데이터(브로커, 토픽, 파티션, 리더 등)를 관리하고, 클러스터 내에서 발생하는 변화(예: 브로커 추가/제거, 장애 감지 등)를 코디네이트하여 시스템 전체의 일관성을 유지합니다.

## **요약 표: 구성 요소 비교**

| **구성 요소** | **주요 기능** | **의존성 변화** |
| --- | --- | --- |
| 브로커 | 데이터 저장/처리, 파티션 관리 | KRaft로 전환 중 |
| 클러스터 | 브로커 집합, 확장성/내결함성 제공 | 독립적 운영 가능 |
| 주키퍼 (레거시) | 메타데이터 관리, 컨트롤러 선출 | Kafka 3.0+에서 제거 |
| KRaft | Raft 기반 메타데이터 관리 | 주키퍼 대체 |
  


  

---  
  

### 여러개의 카프카 클러스터가 연결된 주키퍼

```

                          +---------------------+
                          |     ZooKeeper       |
                          |  (Central Service)  |
                          +---------------------+
                                   / | \
                                  /  |  \
                                 /   |   \
                                /    |    \
              +----------------+   +----------------+   +----------------+
              | Kafka Cluster 1|   | Kafka Cluster 2|   | Kafka Cluster 3|
              +----------------+   +----------------+   +----------------+
              |  Broker 1      |   |  Broker 1      |   |  Broker 1      |
              |  Broker 2      |   |  Broker 2      |   |  Broker 2      |
              |  Broker 3      |   |  Broker 3      |   |  Broker 3      |
              +----------------+   +----------------+   +----------------+

```
  
- 카프카 클러스터를 실행하기 위해서는 주키퍼가 필요함
- 주키퍼의 서로 다른 `znode`에 클러스터를 지정하면 됨
- `root znode`에 각 클러스터별 `znode`를 생성하고 클러스터 실행시 `root`가 아닌 하위 `znode`로 설정
- 카프카 3.0 부터는 주키퍼가 없어도 클러스 동작 가능

> **znode**는 ZooKeeper의 기본 데이터 저장 단위로, 파일 시스템의 디렉터리나 파일과 유사한 개념입니다. ZooKeeper는 계층적(트리 형태) 네임스페이스를 제공하는데, 이 트리의 각 "노드"가 바로 **znode**입니다.
>
> 
  
  
## 브로커의 역할
  
## 컨트롤러
  
클러스터의 다수 브로커 중 한 대가 컨트롤러의 역할을 한다. 컨트롤러는 다른 브로커들의 상태를 체크 및 브로커가 클러스터에서 빠지는경우 해당 브로커에 존재하는 리더 파티션을 재 분배한다.  
  
카프카는 지속적으로 데이터를 처리해야 하므로 브로커의 상태가 비정상이라면 빠르게 클러스터에서 빼내는 것이 중요하다. 이 역 컨트롤러 역할을 하는 브로커에 장애가 생기면 다른 브로커가 해당 엄무를 대체한다.
  
> **리더 파티션**(Leader Partition)은 분산 메시징 시스템(예, Apache Kafka)에서 각 파티션에 할당된 하나의 주체를 의미합니다.  
> 즉, 하나의 토픽이 여러 개의 파티션으로 나뉘어 저장될 때, 각 파티션은 여러 복제본(레플리카)을 가질 수 있는데 그 중 읽기/쓰기 요청을 직접 처리하는 브로커가 바로 리더 파티션입니다.  

---  
  
### 데이터 삭제
  
카프카는 다른 메시징 플랫폼과 다르게 컨슈머가 데이터를 가져가더라도 토픽의 데이터가 삭제되지 않는다. 또한 프로듀서가 데이터 삭제 요청을 할수도 없다.  
   
오직 브로커만이 데이터를 삭제할 수 있다. **데이터 삭제는 파일 단위**로 이루어지는데 이 단위를 `로그 세그먼트`라고 부른다.  
  
이 세그먼트에는 다수의 데이터가 들어 있기 때문에 일반적으로 **데이터베이스처럼 특정 데이터를 선별해서 삭제할 수 없다.**
  
> **delete 옵션**으로  특정 시간, 용량 에따라 데이터를 삭제할 수 있다. 혹은 `compact`옵션을 사용하게 되면 가장 최신의 메세지 레코드를 제외하고 모두 삭제할 수 있다.
  
  

---
  
### 컨슈머 오프셋 저장
  
컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋한다.  
  
즉 컨슈머가 카프카의 파티션의 어느 데이터 레코드까지 데이터를 처리했는지를 그 특정 위치를 알 수 있게 해주는 것을 커밋이라고 한다.
  
커밋한 오프셋은 __consumer_offsets 토픽에 저장한다. 여기에 저장된 오프셋틀 토대로 컨슈머 그룹은 다음 레코드를 가져가서 처리한다.
  
> **오프셋**(offset)은 Kafka에서 각 파티션 내에 저장된 레코드의 순차적인 위치를 나타내는 숫자입니다. 쉽게 말해, 파티션에 기록된 메시지들이 배열된 인덱스와 같은 역할을 합니다.
  
  

---  

### 그룹 코디네이터
그룹 코디네이터는 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할을 한다.  
  
컨슈머가 건슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 동장하는 컨슈머로 할당하여 **끊임없이 데이터가 처리되도록 도와준다.**  
  
파티션을 컨슈머로 **재할당하는 과정**을 **리밸런스**(rebalance)라고 부른다.

## 데이터 저장

카프카를 실행할 때 config/server.properties의 **log.dir 옵션**에 정의한 디렉토리 위치에 데이터를 저장한다. **토픽 이름**과 **파티션 번호의 조합**으로 **하위 디렉토리를 생성**하여 데이터를 저장한다.

hello.kafka 토픽의 0번 파티션에 존재하는 데이터를 확인할 수 있다. **. log**에는 메시지와 메타데이터를 저장하고 **.index**는 메시지의 오프셋을 인덱싱한 정보를 담는 파일이다. **. timeindex** 파일에는 메시지에 포함된 timestamp값을 기준으로 인덱싱한 정보가 담겨있다.

이 메시지란 프로듀서에서 보낸 레코드 ,즉 **하나의 데이터를 메시지**라고 부르고 공식적으로 카프카에서는 이를 **레코드**라고 부른다

```scss
ls/target/kafka-logs
__consumer_offset-0   __consumer_offset-21

........
ls/target/kafka-logs/hello.kafka-0
00000000000.index      00000000000.log
00000000000.timeindex  leader-epoch-checkpoint
```

> **인덱싱(index)한 정보**가 담겨있다는 말은 **메시지 데이터가 저장된 로그 파일 내에서 특정 기준(예: 오프셋, 타임스탬프)을 사용하여 메시지의 물리적 위치(파일 내 바이트 오프셋)를 미리 매핑(mapping)해 놓은 정보**가 저장된 파일을 의미합니다.



### 로그와 세그먼트

```scss
ls/target/kafka-logs/hello.kafka-0
00000000000.log
00000000010.log
00000000020.log
```

카프카는 데이터가 특정 하나의 파일에 연속적으로 데이터가 저장되는 것이 아닌 위에 처럼 여러 파일에 나누어서 저장한다는 특징이 있다.

이렇게 나뉘는 기준은 크게 2가지가 있다. 하나는 바이트단위 이고 하나는 시간단위 이다.

- log.segment.byte : 바이트 단위의 최대 세그먼트 크기 지정. 기본 값은 1GB
- log.roll.ms(hours): 세기먼트가 신규 생성된 이후 다음 파일로 넘어가는 시간 주기. 기본 값은 7

위에 로그 파일을 보면 00.log, 10.log  20.log 라고 적혀 있다. 이 숫자는 오프셋 번호를 나타낸다.

이 오프셋은 레코드의 고유한 번호를 의미한다. 프로듀서가 레코드를 만들어서 브로커로 보내게 되면 파티션중 하나에 데이터가 저장된다 여기서는 **hello.kafka-0(0번 파티션)** 에 데이터가 저장될때 고유

한 번호(숫자)가 새롭게 지정되어서 저장된다.

즉 00.log 에는 0~9번까지의 레코드가, 10.log 에는 10~19 번까지의 레코드가 20.log에는 20~ 이런식으로 레코드가 저장되게 된다.

지금 상황에서 프로듀서에서 새롭게 레코드를 브로커에 전달하게 되면 가장 최신의 세그먼트인 20.log 에 데이터가 저장된다. 이때 가징 최신의 세그먼트, 즉 현재 쓰기가 진행되고 있는 세그먼트를  **active 세그먼트**라고 한다.

이때 우리는 파일명에서 해당 세그먼트를 추정할 수 있다. 세그먼트에 쓰여지는 **최초의 오프셋번호**가 파일명이 된다.

그래서 세그먼트 마다 지정된 바이트만큼 저장하고 다음 세그먼트로 넘어갈 수도 있고 기간이 지나서 다음 세거먼트로 넘어갈 수도 있다.

가장 마지막 세그먼트 파일(쓰기가 일어나고 있는 파일)을 엑티브 세그먼트라고 하고 이 세그먼트는 브로커의 삭제 대상에서 포함되지 않는다. 그 외에 다른 세그먼트는 retention 옵션에 따라 삭제 대상으로 지정할 수 있다.

> **Retention 옵션은** Kafka 브로커가 저장한 로그(세그먼트 파일)에서 **불필요하거나 오래된 데이터를 자동으로 삭제하기 위한 정책**을 의미합니다.